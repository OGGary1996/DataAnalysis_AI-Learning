{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "391b620d",
      "metadata": {
        "id": "391b620d"
      },
      "source": [
        "# Titanic Survival Prediction Using Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepared by : ADRIAN BAHTIAR (000509890)"
      ],
      "metadata": {
        "id": "jC2WNAXPQ3ih"
      },
      "id": "jC2WNAXPQ3ih"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, I use the Naive Bayes algorithm to predict Titanic passenger survival. I cover data preprocessing, model training, and evaluation, focusing on accuracy and other key metrics."
      ],
      "metadata": {
        "id": "NnLGnxL3Pehb"
      },
      "id": "NnLGnxL3Pehb"
    },
    {
      "cell_type": "markdown",
      "id": "13bf3ff4",
      "metadata": {
        "id": "13bf3ff4"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e36aac0c",
      "metadata": {
        "id": "e36aac0c"
      },
      "source": [
        "I'm starting by importing the necessary libraries for data manipulation, visualization, and modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f8dfe8e9",
      "metadata": {
        "id": "f8dfe8e9"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt # data visualization\n",
        "import seaborn as sns # data visualization\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('ggplot')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f284325",
      "metadata": {
        "id": "0f284325"
      },
      "source": [
        "## Load the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cf8605b",
      "metadata": {
        "id": "6cf8605b"
      },
      "source": [
        "Next, I'll load the Titanic dataset into a Pandas DataFrame for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cf3de230",
      "metadata": {
        "id": "cf3de230"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the data\n",
        "titanic_data = pd.read_csv('titanic-dataset.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88fc4249",
      "metadata": {
        "id": "88fc4249"
      },
      "source": [
        "## Initial Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df02423e",
      "metadata": {
        "id": "df02423e"
      },
      "source": [
        "Before diving into preprocessing, I want to understand the structure, data types, and basic statistics of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "de074bd3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "de074bd3",
        "outputId": "807ad7e4-876a-41a0-8146-dee75626332b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Name         891 non-null    object \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Sex          891 non-null    object \n",
            " 4   Age          714 non-null    float64\n",
            " 5   SibSp        891 non-null    int64  \n",
            " 6   Parch        891 non-null    int64  \n",
            " 7   Ticket       891 non-null    object \n",
            " 8   Fare         891 non-null    float64\n",
            " 9   Cabin        204 non-null    object \n",
            " 10  Embarked     889 non-null    object \n",
            " 11  Survived     891 non-null    int64  \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,\n",
              "        PassengerId      Pclass         Age       SibSp       Parch  \\\n",
              " count   891.000000  891.000000  714.000000  891.000000  891.000000   \n",
              " mean    446.000000    2.308642   29.699118    0.523008    0.381594   \n",
              " std     257.353842    0.836071   14.526497    1.102743    0.806057   \n",
              " min       1.000000    1.000000    0.420000    0.000000    0.000000   \n",
              " 25%     223.500000    2.000000   20.125000    0.000000    0.000000   \n",
              " 50%     446.000000    3.000000   28.000000    0.000000    0.000000   \n",
              " 75%     668.500000    3.000000   38.000000    1.000000    0.000000   \n",
              " max     891.000000    3.000000   80.000000    8.000000    6.000000   \n",
              " \n",
              "              Fare    Survived  \n",
              " count  891.000000  891.000000  \n",
              " mean    32.204208    0.383838  \n",
              " std     49.693429    0.486592  \n",
              " min      0.000000    0.000000  \n",
              " 25%      7.910400    0.000000  \n",
              " 50%     14.454200    0.000000  \n",
              " 75%     31.000000    1.000000  \n",
              " max    512.329200    1.000000  ,\n",
              " PassengerId      0\n",
              " Name             0\n",
              " Pclass           0\n",
              " Sex              0\n",
              " Age            177\n",
              " SibSp            0\n",
              " Parch            0\n",
              " Ticket           0\n",
              " Fare             0\n",
              " Cabin          687\n",
              " Embarked         2\n",
              " Survived         0\n",
              " dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "\n",
        "# Information about the dataset\n",
        "data_info = titanic_data.info()\n",
        "\n",
        "# Statistical summary\n",
        "data_stats = titanic_data.describe()\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = titanic_data.isnull().sum()\n",
        "\n",
        "data_info, data_stats, missing_values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "424e5c20",
      "metadata": {
        "id": "424e5c20"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section covers all the data processing I do."
      ],
      "metadata": {
        "id": "SRBZdR58RBGe"
      },
      "id": "SRBZdR58RBGe"
    },
    {
      "cell_type": "markdown",
      "id": "8940da3d",
      "metadata": {
        "id": "8940da3d"
      },
      "source": [
        "### Drop Insignificant Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b837f6de",
      "metadata": {
        "id": "b837f6de"
      },
      "source": [
        "I'll remove columns that are not likely to contribute to the predictive model. These include 'PassengerId', 'Name', 'Ticket', and 'Cabin'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fbe34ab8",
      "metadata": {
        "id": "fbe34ab8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Drop columns that are not significant for the analysis\n",
        "titanic_data.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a446ad9b",
      "metadata": {
        "id": "a446ad9b"
      },
      "source": [
        "### Handle Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f0bff89",
      "metadata": {
        "id": "0f0bff89"
      },
      "source": [
        "Handling missing values is crucial. I'll impute missing 'Age' values with the median and 'Embarked' with the most frequent value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0caab8cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0caab8cf",
        "outputId": "bc9191f9-4311-4492-cc70-507fbee3cc07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pclass      0\n",
              "Sex         0\n",
              "Age         0\n",
              "SibSp       0\n",
              "Parch       0\n",
              "Fare        0\n",
              "Embarked    0\n",
              "Survived    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\n",
        "# Impute missing 'Age' with the median\n",
        "titanic_data['Age'].fillna(titanic_data['Age'].median(), inplace=True)\n",
        "\n",
        "# Impute missing 'Embarked' with the mode\n",
        "titanic_data['Embarked'].fillna(titanic_data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Check for any more missing values\n",
        "titanic_data.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a4fe6ce",
      "metadata": {
        "id": "0a4fe6ce"
      },
      "source": [
        "### One-Hot Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "860fdcd5",
      "metadata": {
        "id": "860fdcd5"
      },
      "source": [
        "I'll convert categorical variables into a format that could be better fed into machine learning algorithms using one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4ee3cbfe",
      "metadata": {
        "id": "4ee3cbfe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Perform one-hot encoding on categorical variables\n",
        "titanic_data = pd.get_dummies(titanic_data, columns=['Pclass', 'Sex', 'Embarked'], drop_first=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65437a90",
      "metadata": {
        "id": "65437a90"
      },
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b425a27a",
      "metadata": {
        "id": "b425a27a"
      },
      "source": [
        "I'll scale the 'Age' and 'Fare' features to standardize their ranges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "eba7efcd",
      "metadata": {
        "id": "eba7efcd"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the Standard Scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Columns to scale\n",
        "scale_cols = ['Age', 'Fare']\n",
        "\n",
        "# Perform feature scaling\n",
        "titanic_data[scale_cols] = scaler.fit_transform(titanic_data[scale_cols])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e130e3b",
      "metadata": {
        "id": "6e130e3b"
      },
      "source": [
        "## Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40af80d8",
      "metadata": {
        "id": "40af80d8"
      },
      "source": [
        "Finally, I'll use a Naive Bayes classifier to make survival predictions. Then, I'll evaluate the model's performance using metrics like accuracy, confusion matrix, and classification report."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've chosen to use accuracy as my primary evaluation metric. Accuracy tells me the ratio of correctly predicted instances out of the total instances in the dataset. It's a great starting point for assessing how well my model is doing. However, I'm also aware that accuracy alone might not give the full picture, especially when the classes are imbalanced. That's why I've also looked at additional metrics like the confusion matrix and the classification report."
      ],
      "metadata": {
        "id": "DxkmGD-2SOaA"
      },
      "id": "DxkmGD-2SOaA"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b285db61",
      "metadata": {
        "id": "b285db61"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Splitting the data\n",
        "X = titanic_data.drop('Survived', axis=1)\n",
        "y = titanic_data['Survived']\n",
        "\n",
        "# 70% training and 30% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Naive Bayes Classifier\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# Fit the model\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = gnb.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy:',accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "NaikrZuPOp24",
        "outputId": "39d24eeb-8e61-4f8c-9dad-484cca152715"
      },
      "id": "NaikrZuPOp24",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.7835820895522388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('conf_matrix:',conf_matrix)\n",
        "print('class_report:',class_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YmIIEoZHOt3c",
        "outputId": "b3684754-0b91-4c6e-f203-90ce3114c7eb"
      },
      "id": "YmIIEoZHOt3c",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conf_matrix: [[128  29]\n",
            " [ 29  82]]\n",
            "class_report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82       157\n",
            "           1       0.74      0.74      0.74       111\n",
            "\n",
            "    accuracy                           0.78       268\n",
            "   macro avg       0.78      0.78      0.78       268\n",
            "weighted avg       0.78      0.78      0.78       268\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}